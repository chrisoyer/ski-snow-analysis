{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7XPDZgpz1Xmc"
   },
   "source": [
    "# Description\n",
    "I will use several deep learning models for my time series predictions. \n",
    "* LSTM\n",
    "* Transformer\n",
    "* dialated CNN\n",
    "\n",
    "In all cases I will include daily snowfall as an exogenous variable.\n",
    "\n",
    "## Environment\n",
    "For $ reasons I will use Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Fxn3mNN1p7b"
   },
   "outputs": [],
   "source": [
    "# get colab status\n",
    "try:\n",
    "    import google.colab\n",
    "    IN_COLAB = True\n",
    "    %tensorflow_version 2.x\n",
    "except:\n",
    "    IN_COLAB = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dL4bZtGo1Xmj"
   },
   "outputs": [],
   "source": [
    "# data wrangling\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path\n",
    "\n",
    "# viz\n",
    "import altair as alt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from vapeplot import vapeplot\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dL4bZtGo1Xmj"
   },
   "outputs": [],
   "source": [
    "# local code with hack to avoid cloing full repo each time colab is run\n",
    "if IN_COLAB:\n",
    "    projectcode = r\"thttps://github.com/chrisoyer/ski-snow-modeling/blob/master/src/analysis/project_utils/project_utils.py\"\n",
    "    ! wget $projectcode\n",
    "from project_utils.project_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "G796MM0Z1XnG"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import sequence\n",
    "from tensorflow.keras import Input, Model\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "g872-Wxf1Xnc"
   },
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UnYmV6rl1Xnd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "alt.renderers.enable(embed_options={'theme': 'vox'})\n",
    "alt.data_transformers.disable_max_rows()\n",
    "#plt_style = r'https://github.com/dhaitz/matplotlib-stylesheets/blob/master/pitayasmoothie-light.mplstyle'\n",
    "#plt.style.use(plt_style)\n",
    "plt.rc('figure', figsize=(11.0, 7.0))\n",
    "batch_size = 30\n",
    "logs_path = \"./logs/visualize_graph\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kn5WQHzc1Xn4"
   },
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_Nh3-o1I16Tb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/User/Documents/GitHub/ski-snow-modeling/src/analysis\n"
     ]
    }
   ],
   "source": [
    "if IN_COLAB:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/gdrive')\n",
    "    os.chdir(r'/content/gdrive/My Drive/data_sci/colab_datasets/ski/')\n",
    "    all_data_path = r'./data/snow_data_clean.parquet'\n",
    "    mirrored_strategy = tf.distribute.MirroredStrategy()\n",
    "else:\n",
    "    all_data_path = r'../../data/snow_data_clean.parquet'\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2iEUM05J1XoA"
   },
   "outputs": [],
   "source": [
    "snow_df = pd.read_parquet(all_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qTeK45hn1Xoc"
   },
   "source": [
    "### Reshape for TF input\n",
    "Shape should match (__samples__, __time steps__, __features__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 67.        ,  18.        ,   0.        ],\n",
       "       [ 68.        ,  18.        ,   0.        ],\n",
       "       [ 69.        ,  18.        ,   0.        ],\n",
       "       ...,\n",
       "       [432.        ,  35.43418834,   0.        ],\n",
       "       [433.        ,  35.56049869,   0.        ],\n",
       "       [434.        ,  35.6400577 ,   0.        ]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Quick& dirty\n",
    "def data_slim(source=snow_df, station=None, region=None):\n",
    "    \"\"\"filters data for station OR region, relevant features, and returns np\"\"\"\n",
    "    if station:\n",
    "        source = source.query('station==@station')\n",
    "    if region:\n",
    "        source = source.query('region==@region')\n",
    "\n",
    "    data_arr = (source\n",
    "                .reset_index()\n",
    "                [['dayofyr', 'base', 'snowfall']]\n",
    "                .to_numpy()\n",
    "                )\n",
    "    return data_arr\n",
    "\n",
    "copper = data_slim(station=\"Copper Mountain\")\n",
    "copper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data=None, test_frac=.2, lookback=30, batch_size=batch_size):\n",
    "    \"\"\"split into train and test sets\n",
    "    Params:\n",
    "        data: input data\n",
    "        test_size: fraction of data for test\n",
    "    returns: (training data generator, test data generator)\n",
    "    \"\"\"\n",
    "    data_rows = data.shape[0] \n",
    "    test_size = int(data_rows * test_frac)\n",
    "    train_size = data_rows - test_size\n",
    "    train, test = data[:train_size, :], data[train_size:, :]\n",
    "    train_data_gen = sequence.TimeseriesGenerator(train, train,\n",
    "                                   length=lookback, sampling_rate=1, stride=1,\n",
    "                                   batch_size=batch_size)\n",
    "    test_data_gen = sequence.TimeseriesGenerator(test, test,\n",
    "                                   length=lookback, sampling_rate=1, stride=1,\n",
    "                                   batch_size=batch_size)\n",
    "    return train_data_gen, test_data_gen\n",
    "X_train, X_test = data_split(data=copper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hXTm9mUC1Xol"
   },
   "source": [
    "# Plotting Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IpVsCYxh4FsB"
   },
   "outputs": [],
   "source": [
    "def error_plotter(history):\n",
    "    \"\"\"plots train and validation scores by epoch\"\"\"\n",
    "    pal =  sns.blend_palette(vapeplot.palette('macplus'))\n",
    "    sns.set_palette(pal)\n",
    "    \n",
    "    loss_train = history.history['train_loss']\n",
    "    loss_val = history.history['val_loss']\n",
    "    plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
    "    plt.plot(epochs, loss_val, 'b', label='Validation loss')\n",
    "    plt.title('Training and Validation loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VoGI33Zl1Xo3"
   },
   "source": [
    "# Timeseries Modeling\n",
    "\n",
    "The evolution of snow base depth over time depends (not 1:1; a foot of powder is only a few inches of packed powder) on new snowfall and melting of old snow. I will start by modeling as a simple timeseries, and then include new snowfall as a predictor variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dkRmq7LH1Xo5"
   },
   "source": [
    "## Modeling Setup\n",
    "I will use supersetting crossvalidation (walk-forward CV) since this is a time series problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0Grps6111XpC"
   },
   "source": [
    "# TF LSTM models\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CpE2UtpO1XpD"
   },
   "outputs": [],
   "source": [
    "# scale data\n",
    "def scaler_factory(X):\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaler = scaler.fit(X)\n",
    "    scaled_X = scaler.transform(X)\n",
    "\n",
    "    # invert transform\n",
    "    inverted_X = scaler.inverse_transform(scaled_X)\n",
    "    return scaler, inverse_scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqOK4Ttb1XpO"
   },
   "outputs": [],
   "source": [
    "def make_lstm(neurons, layers, batch_size, x_shape):\n",
    "    \"\"\"\n",
    "    Parameters:\n",
    "        neurons: width of layers, eg (4,5,6) implies first hidden layer has 4\n",
    "            neuron, 2nd layer has 5, third layer has 6\n",
    "        batch size: ...\n",
    "        x_shape: (rows, features)\n",
    "    Returns: unfitted model\n",
    "    \"\"\"\n",
    "    input_shape = (x_shape[0], x_shape[1])\n",
    "    xlayer = inputs = Input(shape=input_shape, batch_size=batch_size)\n",
    "    for layer in range(layers):\n",
    "        xlayer = LSTM(units=neurons, batch_input_shape=input_shape, \n",
    "                   stateful=True, dropout=0.2, recurrent_dropout=0.2,)(xlayer)\n",
    "    outputs = Dense(1)(xlayer)\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    metrics = ['mean_absolute_error']  # TODO: custom r2 func\n",
    "    model.compile(loss=\"mse\", metrics=metrics,\n",
    "                  optimizer='adam')\n",
    "    return model\n",
    "\n",
    "def fit_model(model, X, batch_size, n_epoch):\n",
    "    \"\"\"runs the training; returns model and history\"\"\"\n",
    "    for i in range(n_epoch):\n",
    "        history = model.fit(X, epochs=n_epoch, batch_size=batch_size, \n",
    "                            verbose=0, shuffle=False, callbacks=[])\n",
    "        model.reset_states()\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqOK4Ttb1XpO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(30, 2925, 3)]           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (30, 100)                 41600     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (30, 1)                   101       \n",
      "=================================================================\n",
      "Total params: 41,701\n",
      "Trainable params: 41,701\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "lstm_100x1 = make_lstm(neurons=100, layers=1,\n",
    "                       batch_size=batch_size, x_shape=copper.shape)\n",
    "lstm_100x1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hqOK4Ttb1XpO",
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": " Trying to access element 31 in a list with 30 elements.\n\t [[{{node model_2/lstm_2/while/body/_1/TensorArrayV2Read/TensorListGetItem}}]] [Op:__inference_train_function_6801]\n\nFunction call stack:\ntrain_function\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-93c1a1fc9033>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m lstm_100x1, lstm_100x1_hst = fit_model(model=lstm_100x1, X=X_train,\n\u001b[1;32m----> 2\u001b[1;33m                                        batch_size=batch_size, n_epoch=10)\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlstm_100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mto_file\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'model.png'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-24-5ae077fb4470>\u001b[0m in \u001b[0;36mfit_model\u001b[1;34m(model, X, batch_size, n_epoch)\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m         history = model.fit(X, epochs=n_epoch, batch_size=batch_size, \n\u001b[1;32m---> 26\u001b[1;33m                             verbose=0, shuffle=False, callbacks=[])\n\u001b[0m\u001b[0;32m     27\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreset_states\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     64\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 66\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     67\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     68\u001b[0m     \u001b[1;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m    846\u001b[0m                 batch_size=batch_size):\n\u001b[0;32m    847\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 848\u001b[1;33m               \u001b[0mtmp_logs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    849\u001b[0m               \u001b[1;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    850\u001b[0m               \u001b[1;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    579\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 580\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    581\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    582\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[1;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m         \u001b[1;31m# stateless function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 644\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    645\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    646\u001b[0m       \u001b[0mcanon_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcanon_kwds\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2418\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2420\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2422\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1665\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1666\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1667\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1744\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[1;32m-> 1746\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[0;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[0;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    599\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32mc:\\users\\user\\documents\\github\\ski-snow-modeling\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[1;32m---> 60\u001b[1;33m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m:  Trying to access element 31 in a list with 30 elements.\n\t [[{{node model_2/lstm_2/while/body/_1/TensorArrayV2Read/TensorListGetItem}}]] [Op:__inference_train_function_6801]\n\nFunction call stack:\ntrain_function\n"
     ]
    }
   ],
   "source": [
    "lstm_100x1, lstm_100x1_hst = fit_model(model=lstm_100x1, X=X_train,\n",
    "                                       batch_size=batch_size, n_epoch=10)\n",
    "\n",
    "plot_model(lstm_100, show_shapes=True, to_file='model.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "raw",
    "id": "nPu8PJ2o1XpU"
   },
   "source": [
    "Batch Size: 1\n",
    "Epochs: 3000\n",
    "Neurons: 4\n",
    "--------------\n",
    "or 1 neuron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u3LJRXSf1XpW"
   },
   "source": [
    "# Compare Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "TF-snow_ts_analysis.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
