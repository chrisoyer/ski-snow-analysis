{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "snow_nonts_analysis.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.6"
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XCGOsNC1F6EV"
      },
      "source": [
        "# Description\n",
        "This will focus on using classic regression models and bayesian models. \n",
        "\n",
        "#### NOTE: As described in EDA notebook, \"Pseudo_ts\" is concatenation of data from locally adjacent ski resorts (e.g., all resorts in Colorado) into a single timeseries.\n",
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hkRrNSaGDae",
        "outputId": "dbecd0fa-c32b-4c65-e6c1-3cb1aea961d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        }
      },
      "source": [
        "! pip install vapeplot arviz pystan stan_utility"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vapeplot in /usr/local/lib/python3.6/dist-packages (0.0.8)\n",
            "Requirement already satisfied: arviz in /usr/local/lib/python3.6/dist-packages (0.10.0)\n",
            "Requirement already satisfied: pystan in /usr/local/lib/python3.6/dist-packages (2.19.1.1)\n",
            "Requirement already satisfied: stan_utility in /usr/local/lib/python3.6/dist-packages (0.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vapeplot) (1.18.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from vapeplot) (3.2.2)\n",
            "Requirement already satisfied: setuptools>=38.4 in /usr/local/lib/python3.6/dist-packages (from arviz) (50.3.0)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.4.1)\n",
            "Requirement already satisfied: netcdf4 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.5.4)\n",
            "Requirement already satisfied: xarray>=0.16.1 in /usr/local/lib/python3.6/dist-packages (from arviz) (0.16.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from arviz) (20.4)\n",
            "Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.6/dist-packages (from arviz) (1.1.2)\n",
            "Requirement already satisfied: Cython!=0.25.1,>=0.22 in /usr/local/lib/python3.6/dist-packages (from pystan) (0.29.21)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from stan_utility) (2.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->vapeplot) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->vapeplot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->vapeplot) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->vapeplot) (2.8.1)\n",
            "Requirement already satisfied: cftime in /usr/local/lib/python3.6/dist-packages (from netcdf4->arviz) (1.2.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->arviz) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.23->arviz) (2018.9)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNlQEkolNSWR",
        "outputId": "dae7152d-757c-4b71-c9d2-a00beca35e66",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "try:\n",
        "    import google.colab\n",
        "    IN_COLAB = True\n",
        "except:\n",
        "    IN_COLAB = False\n",
        "\n",
        "if IN_COLAB:\n",
        "    import os\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    base_path = r'/content/gdrive/My Drive/data_sci/colab/ski/'\n",
        "    os.chdir(base_path)\n",
        "    try:\n",
        "        ! git clone https://github.com/chrisoyer/ski-snow-modeling/\n",
        "    except:  # if dir not empty e.g. already cloned\n",
        "        ! git pullb\n",
        "    mod_path = os.path.join(base_path, \n",
        "                            r\"ski-snow-modeling/src/analysis/project_utils/project_utils.py\")\n",
        "    import importlib.util\n",
        "    spec = importlib.util.spec_from_file_location(name=\"utils.name\", location=mod_path)\n",
        "    utils = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(utils)\n",
        "    \n",
        "    os.chdir('./ski-snow-modeling/src/analysis/')\n",
        "    # Change the working directory to the repo root.\n",
        "    # Add the repo root to the Python path.\n",
        "    import sys\n",
        "    sys.path.append(os.getcwd())\n",
        "else:\n",
        "    # local running\n",
        "    import project_utils as utils"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "fatal: destination path 'ski-snow-modeling' already exists and is not an empty directory.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7TktoEhF6EX",
        "outputId": "7d27e157-68d6-467a-c383-ff18aacb9e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "# data wrangling\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os.path\n",
        "import pickle\n",
        "import calendar\n",
        "\n",
        "# viz\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import seaborn as sns\n",
        "import vapeplot\n",
        "import arviz as az\n",
        "\n",
        "# modeling\n",
        "import pystan\n",
        "import stan_utility\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The autoreload extension is already loaded. To reload it, use:\n",
            "  %reload_ext autoreload\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ed5zssxrF6Eb"
      },
      "source": [
        "# Parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VZB7OgpF6Ec"
      },
      "source": [
        "%config InlineBackend.figure_format = 'retina'\n",
        "plt.style.use('seaborn')\n",
        "plt.rc('figure', figsize=(11.0, 7.0))"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZtJblGFF6Eg"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lndHvFjsF6Eh"
      },
      "source": [
        "file_path = r'../../data/snow_data_clean.parquet'\n",
        "all_data_path = os.path.join(os.getcwd(), file_path)\n",
        "model_path = r'./stan_model.pkl'\n",
        "result_path = r'../../data/processed/stan_results.pkl'"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiLDY-_dF6Ek",
        "outputId": "a5b43acd-443b-430e-aff3-0dd6bba20563",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        }
      },
      "source": [
        "# parquet opening is broken on colab\n",
        "with open(file_path, 'rb') as parq_file:\n",
        "    long_series_df = pd.read_parquet(parq_file)\n",
        "assert long_series_df.base.isna().sum()==0\n",
        "\n",
        "long_series_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>dayofyr</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>base</th>\n",
              "      <th>station</th>\n",
              "      <th>snowfall</th>\n",
              "      <th>ski_yr</th>\n",
              "      <th>state</th>\n",
              "      <th>region</th>\n",
              "      <th>pseudo_ts_delt</th>\n",
              "      <th>pseudo_ski_yr</th>\n",
              "      <th>pseudo_ts</th>\n",
              "      <th>basecol_interpolated</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11085</th>\n",
              "      <td>137.0</td>\n",
              "      <td>2016-01-10</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Mt. Holiday</td>\n",
              "      <td>2.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>michigan</td>\n",
              "      <td>Other</td>\n",
              "      <td>324.0</td>\n",
              "      <td>-31.0</td>\n",
              "      <td>1692-01-10</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11086</th>\n",
              "      <td>138.0</td>\n",
              "      <td>2016-01-11</td>\n",
              "      <td>-2.320142</td>\n",
              "      <td>Mt. Holiday</td>\n",
              "      <td>3.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>michigan</td>\n",
              "      <td>Other</td>\n",
              "      <td>324.0</td>\n",
              "      <td>-31.0</td>\n",
              "      <td>1692-01-11</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11087</th>\n",
              "      <td>139.0</td>\n",
              "      <td>2016-01-12</td>\n",
              "      <td>-2.320142</td>\n",
              "      <td>Mt. Holiday</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>michigan</td>\n",
              "      <td>Other</td>\n",
              "      <td>324.0</td>\n",
              "      <td>-31.0</td>\n",
              "      <td>1692-01-12</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11088</th>\n",
              "      <td>140.0</td>\n",
              "      <td>2016-01-13</td>\n",
              "      <td>6.737995</td>\n",
              "      <td>Mt. Holiday</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>michigan</td>\n",
              "      <td>Other</td>\n",
              "      <td>324.0</td>\n",
              "      <td>-31.0</td>\n",
              "      <td>1692-01-13</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11089</th>\n",
              "      <td>141.0</td>\n",
              "      <td>2016-01-14</td>\n",
              "      <td>10.000000</td>\n",
              "      <td>Mt. Holiday</td>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>michigan</td>\n",
              "      <td>Other</td>\n",
              "      <td>324.0</td>\n",
              "      <td>-31.0</td>\n",
              "      <td>1692-01-14</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       dayofyr  timestamp  ...  pseudo_ts basecol_interpolated\n",
              "11085    137.0 2016-01-10  ... 1692-01-10                 True\n",
              "11086    138.0 2016-01-11  ... 1692-01-11                 True\n",
              "11087    139.0 2016-01-12  ... 1692-01-12                 True\n",
              "11088    140.0 2016-01-13  ... 1692-01-13                False\n",
              "11089    141.0 2016-01-14  ... 1692-01-14                False\n",
              "\n",
              "[5 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vfg37-k3F6En"
      },
      "source": [
        "# Feature Engineering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcKhhazNF6En"
      },
      "source": [
        "def add_month(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    return data.assign(month=lambda x:\n",
        "                       x.pseudo_ts.dt.month)\n",
        "\n",
        "def add_diff(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\" use difference in base, not absolute value \"\"\"\n",
        "    return (data\n",
        "            .assign(delta_base=lambda x: x.base.diff(1))\n",
        "            .fillna(0)\n",
        "            .drop(columns=['base'])\n",
        "           )\n",
        "\n",
        "def ohe(data: pd.DataFrame, col: str) -> pd.DataFrame:\n",
        "    return pd.concat([data.drop(columns=[col]),\n",
        "                      pd.get_dummies(data[col],\n",
        "                                     prefix=col)],\n",
        "                     axis=1)\n",
        "\n",
        "def add_month_x_snowfall(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"adds interaction terms\"\"\"\n",
        "    months = [col for col in data.columns\n",
        "              if 'month_' in col]\n",
        "    combos_df = pd.concat([pd.Series(data.snowfall * data[month],\n",
        "                                     name='snowfall_x_' + month)\n",
        "                           for month in months], axis=1)\n",
        "    return pd.concat([data, combos_df], axis=1)\n",
        "\n",
        "def cleaner(data: pd.DataFrame, includes: list=[None]) -> pd.DataFrame:\n",
        "    \"\"\" Removes interpolated rows and unneeded columns\n",
        "    Params:\n",
        "        data: df to operate on\n",
        "        includes: column names NOT to drop (don't need to specify usually)\n",
        "    ski_yr is needed for test/train split\"\"\"\n",
        "    data = data.query('basecol_interpolated==False')\n",
        "    bad_cols = ['dayofyr', 'station', 'state', 'pseudo_ski_yr',\n",
        "                'timestamp', 'basecol_interpolated', 'pseudo_ts',\n",
        "                'pseudo_ts_delt'\n",
        "               ]\n",
        "    bad_cols = [col for col in bad_cols if col not in includes]\n",
        "    return data.drop(columns=bad_cols)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI5Yw01cF6Er",
        "outputId": "e0020f91-624e-46c4-ddd2-01db58c9f0f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        }
      },
      "source": [
        "data = (long_series_df.pipe(add_month)\n",
        "        .pipe(add_diff)\n",
        "        .pipe(ohe, 'month')\n",
        "        .pipe(add_month_x_snowfall)\n",
        "        .pipe(cleaner)\n",
        ")\n",
        "data.sum()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:numexpr.utils:NumExpr defaulting to 2 threads.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "snowfall                                                          239805\n",
              "ski_yr                                                            847944\n",
              "region                 OtherOtherOtherOtherOtherOtherOtherOtherOtherO...\n",
              "delta_base                                                       57308.9\n",
              "month_1                                                            53318\n",
              "month_2                                                            47936\n",
              "month_3                                                            45183\n",
              "month_4                                                            14427\n",
              "month_5                                                             1734\n",
              "month_6                                                              357\n",
              "month_7                                                               94\n",
              "month_8                                                               14\n",
              "month_9                                                                3\n",
              "month_10                                                             328\n",
              "month_11                                                            8716\n",
              "month_12                                                           39818\n",
              "snowfall_x_month_1                                                 54429\n",
              "snowfall_x_month_2                                                 61551\n",
              "snowfall_x_month_3                                                 47591\n",
              "snowfall_x_month_4                                                 13534\n",
              "snowfall_x_month_5                                                   982\n",
              "snowfall_x_month_6                                                    33\n",
              "snowfall_x_month_7                                                     0\n",
              "snowfall_x_month_8                                                     0\n",
              "snowfall_x_month_9                                                     0\n",
              "snowfall_x_month_10                                                  242\n",
              "snowfall_x_month_11                                                 9598\n",
              "snowfall_x_month_12                                                51845\n",
              "dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zOrDuSh-xA-4",
        "outputId": "feaed5de-bfe3-4f46-9a11-5ec443bae339",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 384
        }
      },
      "source": [
        "long_series_df.station.value_counts().head(20)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Seven Springs          3693\n",
              "Bristol Mountain       3670\n",
              "Hilltop                3657\n",
              "Mount Southington      3650\n",
              "Yawgoo Valley          3648\n",
              "Aspen / Snowmass       3647\n",
              "Mt. Shasta Ski Park    3642\n",
              "Chestnut Mountain      3636\n",
              "White Pass             3636\n",
              "Eldora                 3630\n",
              "Diamond Peak           3623\n",
              "Wachusett Mountain     3619\n",
              "Sugar Bowl             3618\n",
              "Hogadon Basin          3618\n",
              "Monarch                3613\n",
              "Kelly Canyon           3602\n",
              "Silverton              3599\n",
              "Lost Valley            3590\n",
              "Heavenly               3390\n",
              "Holiday Valley         3381\n",
              "Name: station, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_m1rP0cIF6FR"
      },
      "source": [
        "# Bayesian Model in Stan (MCMC)\n",
        "I want to add priors to the model that snowfall should only result in increases in base depth, and monthly effects should only result in reduction (i.e., monthly effect should measure strength of melting.); changes at odds with this should be considered as noise. A bayesian model allows for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "__OGwbNgF6FR",
        "outputId": "dde74370-44a0-4cca-c991-14b199fb5dc0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        }
      },
      "source": [
        "# set aside some data for multi-step analysis\n",
        "leaveouts = ['Eldora', 'Seven Springs']\n",
        "stan_multistep_test_df = long_series_df.query('station in @leaveouts')\n",
        "\n",
        "\n",
        "stan_df = (long_series_df\n",
        "           .pipe(add_month)\n",
        "           .pipe(add_diff)\n",
        "           .pipe(ohe, 'region')\n",
        "           .pipe(ohe, 'month')\n",
        "           .pipe(cleaner)\n",
        "           )\n",
        "stan_df.head()\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>snowfall</th>\n",
              "      <th>ski_yr</th>\n",
              "      <th>delta_base</th>\n",
              "      <th>region_Cascades</th>\n",
              "      <th>region_Colorado</th>\n",
              "      <th>region_East</th>\n",
              "      <th>region_New_England</th>\n",
              "      <th>region_Other</th>\n",
              "      <th>region_Rockies_Other</th>\n",
              "      <th>region_Sierras</th>\n",
              "      <th>region_Utah</th>\n",
              "      <th>month_1</th>\n",
              "      <th>month_2</th>\n",
              "      <th>month_3</th>\n",
              "      <th>month_4</th>\n",
              "      <th>month_5</th>\n",
              "      <th>month_6</th>\n",
              "      <th>month_7</th>\n",
              "      <th>month_8</th>\n",
              "      <th>month_9</th>\n",
              "      <th>month_10</th>\n",
              "      <th>month_11</th>\n",
              "      <th>month_12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>11088</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>9.058137</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11089</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>3.262005</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11090</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11091</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11092</th>\n",
              "      <td>0.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       snowfall  ski_yr  delta_base  ...  month_10  month_11  month_12\n",
              "11088       0.0     5.0    9.058137  ...         0         0         0\n",
              "11089       0.0     5.0    3.262005  ...         0         0         0\n",
              "11090       0.0     5.0    0.000000  ...         0         0         0\n",
              "11091       0.0     5.0    0.000000  ...         0         0         0\n",
              "11092       0.0     5.0    0.000000  ...         0         0         0\n",
              "\n",
              "[5 rows x 23 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_7mt-C1Vi60"
      },
      "source": [
        "# sample data; half million records => slow mcmc\n",
        "\n",
        "def sample_weighted_season(df: pd.DataFrame)->pd.DataFrame:\n",
        "    \"\"\"samples dataframe but doesn't remove rare months and mildly reduces\n",
        "    amount of semi-rare months\"\"\"\n",
        "    # un-OHE\n",
        "    df['month'] = df[[c for c in data.columns if \"month_\" in c and \"x_m\" not in c]].idxmax(axis=1)\n",
        "    # define months\n",
        "    rare_months = [f'month_{i}' for i in range(5,11)]\n",
        "    semirare_months = ['month_4', 'month_11']\n",
        "    nonrare_months = ['month_12', 'month_1', 'month_2', 'month_3']\n",
        "    # split and sample data\n",
        "    rare_data = df.query('month in @rare_months')\n",
        "    semirare_data = df.query('month in @semirare_months').sample(frac=.3, axis=0)\n",
        "    nonrare_data = df.query('month in @nonrare_months').sample(frac=.09, axis=0)\n",
        "    # recombine\n",
        "    return pd.concat([rare_data, semirare_data, nonrare_data], axis=0).drop(columns=['month'])\n",
        "\n",
        "# split data first so rare months get included in both sets\n",
        "stan_sample_test_df = stan_df.sample(frac=.20, axis=0)\n",
        "stan_sample_train_df = stan_df.drop(index=stan_sample_test_df.index)\n",
        "# reduce data size \n",
        "stan_sample_test_df = stan_df.pipe(sample_weighted_season)\n",
        "stan_sample_train_df = stan_df.pipe(sample_weighted_season)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RL_pNkXf5Vob"
      },
      "source": [
        "# provide data including shapes and column type locations to stan\n",
        "columns = stan_df.columns\n",
        "region_cols = [c for c in columns if \"region\" in c]\n",
        "month_cols = [col for col in stan_sample_train_df.columns if \"month\" in col]\n",
        "\n",
        "def subsets(df: pd.DataFrame)-> tuple:\n",
        "    X = df.drop(columns=['delta_base'])\n",
        "    Xmonth= X[month_cols]\n",
        "    Xsnow = X['snowfall']\n",
        "    Xregion = X[region_cols]\n",
        "    y = df[['delta_base']]\n",
        "    return (X, Xmonth, Xsnow, Xregion, y)\n",
        "\n",
        "X, X_month, X_snow, X_region, y = subsets(stan_sample_train_df)\n",
        "X_test, X_month_test, X_snow_test, X_region_test, _ = subsets(stan_sample_test_df)\n",
        "\n",
        "stan_data = {'N': X.shape[0],\n",
        "             'K_month': X_month.shape[1],\n",
        "             'X_month': X_month.to_numpy(),\n",
        "             'K_reg': X_region.shape[1],\n",
        "             'X_reg': X_region.to_numpy(),\n",
        "             'X_snow': X_snow.to_numpy().reshape(-1,1),\n",
        "             'y': y.to_numpy().reshape(-1),\n",
        "             # test\n",
        "             'N_test': X_test.shape[0],\n",
        "             'X_month_test': X_month_test.to_numpy(),\n",
        "             'X_reg_test': X_region_test.to_numpy(),\n",
        "             'X_snow_test': X_snow_test.to_numpy().reshape(-1,1),\n",
        "             }"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rxc7NygqF6FU"
      },
      "source": [
        "stan_model_str = \"\"\"\n",
        "functions {}\n",
        "data {\n",
        "    // input data passed from Python\n",
        "    int<lower=1> N;               // number of data observations\n",
        "    int<lower=1> K_month;         // no of melting predictor\n",
        "    matrix[N, K_month] X_month;   // predictor for melting features\n",
        "    int<lower=1> K_reg;           // no of region features\n",
        "    matrix[N, K_reg] X_reg;       // region predictors\n",
        "    matrix[N, 1] X_snow;          // snowfall predictor\n",
        "    vector[N] y;                  // response vector\n",
        "    \n",
        "    // test variables\n",
        "    int<lower=1> N_test;                  // no of test records\n",
        "    matrix[N_test, K_month] X_month_test; // predictor for melting features\n",
        "    matrix[N_test, K_reg] X_reg_test;     // region predictors\n",
        "    matrix[N_test, 1] X_snow_test;\n",
        "}\n",
        "transformed data {\n",
        "    matrix[N, K_reg] X_reg_snow;\n",
        "    row_vector[N] X_snow_rvect = to_row_vector(X_snow);\n",
        "    matrix[N_test, K_reg] X_reg_snow_test;\n",
        "    row_vector[N_test] X_snow_rvect_test = to_row_vector(X_snow_test);\n",
        "    \n",
        "    for (k in 1:K_reg) {          //  K_regxN * Nx1  T\n",
        "        for (n in 1:N) {\n",
        "            X_reg_snow[n,k] = X_snow_rvect[n] * X_reg[n,k];\n",
        "    }  }\n",
        "    \n",
        "    // same, but for test. Should do this with a function...\n",
        "    for (k in 1:K_reg) {\n",
        "        for (n in 1:N_test) {\n",
        "            X_reg_snow_test[n,k] = X_snow_rvect_test[n] * X_reg_test[n,k];\n",
        "    }  }\n",
        "}\n",
        "parameters {\n",
        "    // intercept was causing divergences and coef interpretation \n",
        "    // makes more sense without intercept: \n",
        "    // I don't expect change in base depth absent melting or snowfall\n",
        "    vector<upper=0>[K_month] beta_mo;           // coefficients for melting\n",
        "    vector<lower=0, upper=1>[K_reg] beta_reg_snow;       // coef for region x snow interaction\n",
        "    real<lower=0> sigma;                        // must be +ve\n",
        "    real<lower=0> sig_mos;                      // must be +ve\n",
        "}\n",
        "transformed parameters {\n",
        "}\n",
        "model {\n",
        "    vector[N] mu;                       // y_hat\n",
        "    sigma ~ cauchy(0, 10);              // half Cauchy\n",
        "    sig_mos ~ cauchy(0, 20);\n",
        "    for (n in 1:K_month) {\n",
        "        beta_mo[n] ~ normal(0, sig_mos) T[,0]; // sample from normal, only -ve\n",
        "    }\n",
        "    // prior on snow columns is beta over [0,1]\n",
        "    beta_reg_snow ~ beta(2.2, 3);         // reparameterize so this and snow are from beta dist\n",
        "    mu = X_month*beta_mo + X_reg_snow*beta_reg_snow;\n",
        "    y ~ normal(mu, sigma);\n",
        "}\n",
        "generated quantities{\n",
        "    vector[N_test] y_test;\n",
        "    for(n in 1:N_test) {\n",
        "        y_test[n] = normal_rng(X_month_test[n]*beta_mo + \n",
        "                               X_reg_snow_test[n]*beta_reg_snow, sigma);\n",
        "    }\n",
        "}\n",
        "\"\"\""
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffQAVs5kt23C",
        "outputId": "9833a5d1-0c2a-414b-de56-9faeec09c78f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sm = pystan.StanModel(model_code=stan_model_str, model_name='stan_model')"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pystan:COMPILING THE C++ CODE FOR MODEL stan_model_9ef8f4c0b8e822c1507c3465e9c985ca NOW.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JT3bX-l5ocXx"
      },
      "source": [
        "# avoid recompile if possible\n",
        "with open(model_path, 'wb') as f:\n",
        "    pickle.dump(sm, f)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wD_ZZ4pquEND",
        "outputId": "1814aabf-68ae-4897-d0c8-17c9b609bee2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "fit = sm.sampling(data=stan_data, iter=2_000, chains=4, n_jobs=-1,\n",
        "                  sample_file=\"../../data/processed/stan_samples\",\n",
        "                  control={'adapt_delta': 0.85, # p accepting posterior draw\n",
        "                           'stepsize': 1,  # just starting stepsize\n",
        "                          }, \n",
        "                  seed=42, verbose=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:pystan:Maximum (flat) parameter count (1000) exceeded: skipping diagnostic tests for n_eff and Rhat.\n",
            "To run all diagnostics call pystan.check_hmc_diagnostics(fit)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJXVG5wGhUeI",
        "outputId": "8891449c-5606-4ce6-8105-4461d7aaf2ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "# for overnight run\n",
        "try:\n",
        "    with open(result_path, 'wb') as f:\n",
        "        pickle.dump(fit, f)\n",
        "# reload saved objects if not reruning sampler\n",
        "except NameError:\n",
        "    with open(model_path, 'rb') as f:\n",
        "        sm = pickle.load(f)\n",
        "    with open(result_path, 'rb') as f:\n",
        "        fit = pickle.load(f)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Pickling fit objects is an experimental feature!\n",
            "The relevant StanModel instance must be pickled along with this fit object.\n",
            "When unpickling the StanModel must be unpickled first.\n",
            "  after removing the cwd from sys.path.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWB3_b-Fx7Dp"
      },
      "source": [
        "## MCMC Diagnostics\n",
        "We will want to check:\n",
        "1. Model actually runs.\n",
        "1. Good Mixing of Chains: (fix with stronger prior, reparameterization)\n",
        "    1. $\\hat{R}$ is 1.1 or under for all parameters.\n",
        "    1. When n_eff / n_transitions < 0.001 the estimators that we use are often biased and can significantly overestimate the true effective sample size.\n",
        "1. Check tree depth:\n",
        "if threshold saturated, increase tree depth _control={max_treedepth: 15}_\n",
        "1. \n",
        "\n",
        "_\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6os_UmnszhB",
        "outputId": "7303e782-57d3-4d18-9dee-0ed4799e740a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 769
        }
      },
      "source": [
        "fit_summary = fit.summary()\n",
        "fit_summary.keys()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['__class__',\n",
              " '__contains__',\n",
              " '__delattr__',\n",
              " '__delitem__',\n",
              " '__dict__',\n",
              " '__dir__',\n",
              " '__doc__',\n",
              " '__eq__',\n",
              " '__format__',\n",
              " '__ge__',\n",
              " '__getattribute__',\n",
              " '__getitem__',\n",
              " '__gt__',\n",
              " '__hash__',\n",
              " '__init__',\n",
              " '__init_subclass__',\n",
              " '__iter__',\n",
              " '__le__',\n",
              " '__len__',\n",
              " '__lt__',\n",
              " '__ne__',\n",
              " '__new__',\n",
              " '__reduce__',\n",
              " '__reduce_ex__',\n",
              " '__repr__',\n",
              " '__reversed__',\n",
              " '__setattr__',\n",
              " '__setitem__',\n",
              " '__sizeof__',\n",
              " '__str__',\n",
              " '__subclasshook__',\n",
              " 'clear',\n",
              " 'copy',\n",
              " 'fromkeys',\n",
              " 'get',\n",
              " 'items',\n",
              " 'keys',\n",
              " 'move_to_end',\n",
              " 'pop',\n",
              " 'popitem',\n",
              " 'setdefault',\n",
              " 'update',\n",
              " 'values']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JSPHbBtmns3M",
        "outputId": "5a62b857-ae70-45c9-ce68-7790d0a8e29b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        }
      },
      "source": [
        "stan_utility.check_all_diagnostics(fit)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-ae5562fa4833>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mstan_utility\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheck_all_diagnostics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stan_utility/utils.py\u001b[0m in \u001b[0;36mcheck_all_diagnostics\u001b[0;34m(fit, max_treedepth, quiet)\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m         \u001b[0mcheck_n_eff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mcheck_rhat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         \u001b[0mcheck_div\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/stan_utility/utils.py\u001b[0m in \u001b[0;36mcheck_n_eff\u001b[0;34m(fit, quiet)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcheck_n_eff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquiet\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0;34m\"\"\"Checks the effective sample size per iteration\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     \u001b[0mfit_summary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m     \u001b[0mn_effs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfit_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0mnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_summary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'summary_rownames'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mstanfit4stan_model_9ef8f4c0b8e822c1507c3465e9c985ca_4326186245993221966.pyx\u001b[0m in \u001b[0;36mstanfit4stan_model_9ef8f4c0b8e822c1507c3465e9c985ca_4326186245993221966.StanFit4Model.summary\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pystan/misc.py\u001b[0m in \u001b[0;36m_summary\u001b[0;34m(fit, pars, probs, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mprobs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.75\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.975\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_summary_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m     \u001b[0;31m# TODO: include sem, ess and rhat: ss['ess'], ss['rhat']\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m     \u001b[0ms1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sem'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msd'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quan'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ess'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rhat'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pystan/misc.py\u001b[0m in \u001b[0;36m_summary_sim\u001b[0;34m(sim, pars, probs)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mtidx_rowm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtidx_rowm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mtidx_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtidx_colm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0mlmsdq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_par_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtidx_colm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0mmsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msd'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlmsdq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mquan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quan'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlmsdq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pystan/misc.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0mtidx_rowm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitertools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtidx_rowm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mtidx_len\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtidx_colm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0mlmsdq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_get_par_summary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtidx_colm\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0mmsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'msd'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlmsdq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m     \u001b[0mquan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrow_stack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'quan'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlmsdq\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pystan/misc.py\u001b[0m in \u001b[0;36m_get_par_summary\u001b[0;34m(sim, n, probs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mqfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmquantiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mc_msd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsdfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     \u001b[0mc_quan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mmsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsdfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pystan/misc.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[0mqfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmquantiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m     \u001b[0mc_msd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsdfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 391\u001b[0;31m     \u001b[0mc_quan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    392\u001b[0m     \u001b[0mass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    393\u001b[0m     \u001b[0mmsd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsdfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mass\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pystan/misc.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(chain)\u001b[0m\n\u001b[1;32m    387\u001b[0m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minc_warmup\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m     \u001b[0mmsdfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mddof\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 389\u001b[0;31m     \u001b[0mqfun\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmquantiles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    390\u001b[0m     \u001b[0mc_msd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmsdfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m     \u001b[0mc_quan\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mqfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/mstats_basic.py\u001b[0m in \u001b[0;36mmquantiles\u001b[0;34m(a, prob, alphap, betap, axis, limit)\u001b[0m\n\u001b[1;32m   2650\u001b[0m     \u001b[0;31m# Computes quantiles along axis (or globally)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2652\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_quantiles1D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2653\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_quantiles1D\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/scipy/stats/mstats_basic.py\u001b[0m in \u001b[0;36m_quantiles1D\u001b[0;34m(data, m, p)\u001b[0m\n\u001b[1;32m   2635\u001b[0m         \u001b[0maleph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2636\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maleph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2637\u001b[0;31m         \u001b[0mgamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maleph\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2638\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mgamma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mgamma\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2639\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, casting, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m         return _clip_dep_invoke_with_casting(\n\u001b[0;32m--> 132\u001b[0;31m             um.clip, a, min, max, out=out, casting=casting, **kwargs)\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_clip_dep_invoke_with_casting\u001b[0;34m(ufunc, out, casting, *args, **kwargs)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# try to deal with broken casting rules\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_UFuncOutputCastingError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Numpy 1.17.0, 2019-02-24\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtAQQbXgoJM4"
      },
      "source": [
        "# fix brackets in col nmaes\n",
        "fit_df = (fit.to_dataframe()\n",
        "          .rename(columns=lambda x: x.replace(\"[\", \"_\"))\n",
        "          .rename(columns=lambda x: x.replace(\"]\", \"\")))\n",
        "\n",
        "fit_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LatVl9EK8ELg"
      },
      "source": [
        "### Check test set metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7-L230X7ses",
        "outputId": "86b929b7-a566-4d09-9c3f-a9aff672c686",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y_pred = pd.DataFrame(data=fit.extract(['y_test'], inc_warmup=False)['y_test'].T.mean(axis=1),\n",
        "                      columns=['y_pred'])\n",
        "test_results = pd.concat([y_test.reset_index(drop=True), y_pred], axis=1)\n",
        "\n",
        "r2_score(y_true=test_results.delta_base, y_pred=test_results.y_pred, )"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.022973038159297965"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRP1syFLBIb6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiBiPS4n-Boz"
      },
      "source": [
        "## Visualization of results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-i-s8UKnjA8"
      },
      "source": [
        "fit_az = az.from_pystan(posterior=fit,\n",
        "                        dims={'beta_reg_snow': ['Coefficients_for_Snow_by_Region'],\n",
        "                              'beta_mo': ['Melting_Coefficients_by_Month']},\n",
        "                        coords={'Coefficients_for_Snow_by_Region': X_region.columns.values.tolist(),\n",
        "                                'Melting_Coefficients_by_Month': [calendar.month_name[i+1] for i in range(12)]}\n",
        "                        )\n",
        "rc = {'plot.max_subplots': None}\n",
        "az.rcParams.update(rc)\n",
        "sns.set_style('whitegrid')\n",
        "az.plot_trace(fit_az)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qnInGaRAaRfY"
      },
      "source": [
        "# get region names without \"region_\"\n",
        "region_names = [reg[7:] for reg in X_region.columns.values.tolist()]\n",
        "\n",
        "region_betas_df = fit_df.filter(regex=\"reg\", axis=1)\n",
        "reg_cols = region_betas_df.columns\n",
        "region_betas_df = (region_betas_df\n",
        "                   .rename(columns={col: reg_name for col, reg_name \n",
        "                                    in zip(reg_cols, region_names)})\n",
        "                   .melt(var_name=\"region\"))\n",
        "region_betas_df.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uE97qf4OZxiU"
      },
      "source": [
        "plt.style.use('bmh')\n",
        "fig = sns.kdeplot(x=region_betas_df.value, hue=region_betas_df.region, fill=True, cut=0, bw_adjust=.3)\n",
        "plt.suptitle(\"Estimated Base Increase per Unit of Snowfall\", fontsize=20)\n",
        "plt.xlabel(\"Effect of Unit of Powder\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2D_363pltuR"
      },
      "source": [
        "plt.style.use('ggplot')\n",
        "jazzcup = sns.blend_palette(vapeplot.palette(\"jazzcup\"), n_colors=region_betas_df.region.unique().size)\n",
        "f, ax = plt.subplots(figsize=(12, 8))\n",
        "sort_order = region_betas_df.groupby(['region']).mean().sort_values(by='value', ascending=True).index\n",
        "\n",
        "sns.violinplot(x='region', y='value', data=region_betas_df,\n",
        "            order=sort_order, palette=jazzcup)\n",
        "\n",
        "plt.title(\"Estimated Base Increase per Unit of Snowfall: Bayesian Model\", fontsize=20)\n",
        "plt.xlabel('Region')\n",
        "plt.ylabel('Fraction of Full Unit of Powder');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twx31uBSsgyN"
      },
      "source": [
        "month_betas_df = fit_df.filter(like='beta_mo').melt(var_name=\"month\")\n",
        "month_betas_df = month_betas_df[month_betas_df.value > month_betas_df.value.quantile(.02)]\n",
        "month_map = {f\"beta_mo_{i}\": calendar.month_abbr[i] for i in range(1, 13)}\n",
        "#month_betas_df['month'] = pd.to_datetime(month_betas_df['month'].replace(month_map), format=\"%B\").dt.month.astype('category')\n",
        "month_betas_df['month'] = month_betas_df['month'].replace(month_map).astype('str')\n",
        "month_betas_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxXKPQVlt_gB"
      },
      "source": [
        "def plot_snow_betas(df, start_mo):\n",
        "    fig, ax = plt.subplots()\n",
        "    month_ordered = [mo for mo in calendar.month_abbr[1:] if mo in df.month.unique()]\n",
        "    start_mo_ix = month_ordered.index(start_mo)\n",
        "    month_ordered = month_ordered[start_mo_ix:] + month_ordered[:start_mo_ix]\n",
        "    sns.boxplot(data=df, y='value', x='month', order=month_ordered,\n",
        "                ax=ax, )\n",
        "    ax.set_ylabel('Inches Melted per Day')\n",
        "    ax.set_xlabel('Month')\n",
        "    ax.set_title('Estimated Snow Melted per Day by Month');\n",
        "plot_snow_betas(month_betas_df, \"Jan\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RPhSA24RJfJD"
      },
      "source": [
        "These estimates are mostly expected, but there seems to be low melting amounts during summer...this can be explained when we realize that most of the values for May-November were interpolated. The averages aren't weighted by ski acreage, so the large number of small ski stations on the east coast & midwest with short seasons are disproportionately affecting these numbers. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blPU-QZ4HHce"
      },
      "source": [
        "interpo_ratios=(long_series_df\n",
        "    .assign(month=lambda x: x.pseudo_ts.dt.month)\n",
        "    .groupby('month')\n",
        "    .apply(lambda x: x.basecol_interpolated.sum()/x.shape[0])\n",
        "    .to_frame()\n",
        "    .reset_index()\n",
        "    .rename(columns={0:'ratio'})\n",
        ")\n",
        "fig, ax = plt.subplots()\n",
        "sns.barplot(data=interpo_ratios, x='month', y='ratio', ax=ax)\n",
        "plt.title('Fraction of Base observations that were interpolated', fontsize=15)\n",
        "[plt.text((i-.17), value+.01, str(value)) for i, value in enumerate(interpo_ratios.ratio.round(2).to_numpy())]\n",
        "months_xticks(ax);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhsp01-EJze7"
      },
      "source": [
        "plot_snow_betas(month_betas_df[~month_betas_df.month.isin(['Jun', 'Jul', 'Aug', 'Sep', 'Oct'])], \"Nov\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hJgH7yRoKqRv"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}